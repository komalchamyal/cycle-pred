{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36c42ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install numpy pandas statsmodels matplotlib seaborn scikit-learn\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af69b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cfdd0de5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2025-03-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2025-05-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2025-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2025-07-30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2025-02-20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   start_date\n",
       "0  2025-03-29\n",
       "1  2025-05-23\n",
       "2  2025-07-01\n",
       "3  2025-07-30\n",
       "4  2025-02-20"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 1. Load data ===\n",
    "file_path = \"startDates.csv\"\n",
    "\n",
    "if file_path.endswith(\".csv\"):\n",
    "    df_raw = pd.read_csv(file_path)\n",
    "else:\n",
    "    df_raw = pd.read_excel(file_path)\n",
    "\n",
    "df_raw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1b7d44ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  start_date\n",
       "0 2021-09-29\n",
       "1 2021-11-09\n",
       "2 2021-12-15\n",
       "3 2022-01-11\n",
       "4 2022-02-09"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Preprocess dates\n",
    "df = df_raw.copy()\n",
    "df['start_date'] = pd.to_datetime(df['start_date'])\n",
    "df = df.sort_values('start_date').reset_index(drop=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f50e3717",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_date</th>\n",
       "      <th>cycle_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-09-29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-11-09</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-12-15</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-11</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-09</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  start_date  cycle_length\n",
       "0 2021-09-29           NaN\n",
       "1 2021-11-09          41.0\n",
       "2 2021-12-15          36.0\n",
       "3 2022-01-11          27.0\n",
       "4 2022-02-09          29.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === 2. Compute cycle lengths (in days) ===\n",
    "df['cycle_length'] = df['start_date'].diff().dt.days\n",
    "cycle_lengths = df['cycle_length'].dropna().astype(int)\n",
    "\n",
    "df.head()\n",
    "# cycle_lengths.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5568611",
   "metadata": {},
   "source": [
    "EDA for trend and seasonality, stationary series test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce384a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Plot the raw data\n",
    "df[\"cycle_length\"].plot(title=\"Cycle Length Over Time\", figsize=(10,5))\n",
    "plt.show()\n",
    "\n",
    "# 2. Rolling mean & std (to check trend/volatility)\n",
    "df[\"cycle_length\"].rolling(window=5).mean().plot(label=\"Rolling Mean\")\n",
    "df[\"cycle_length\"].rolling(window=5).std().plot(label=\"Rolling Std\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 3. Autocorrelation plots (to check seasonality patterns)\n",
    "plot_acf(df[\"cycle_length\"], lags=20)\n",
    "plt.show()\n",
    "\n",
    "plot_pacf(df[\"cycle_length\"], lags=20)\n",
    "plt.show()\n",
    "\n",
    "# 4. Stationarity test (ADF test)\n",
    "result = adfuller(df[\"cycle_length\"].dropna())\n",
    "print(\"ADF Statistic:\", result[0])\n",
    "print(\"p-value:\", result[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bcbec39",
   "metadata": {},
   "source": [
    "final comparision over models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "877eb3fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance on Test Data\n",
      "ES: MAE=10.26, RMSE=13.13, MAPE=21.51%, Accuracy=78.49%, ±3-day=12.50%\n",
      "ARIMA: MAE=9.10, RMSE=12.00, MAPE=18.97%, Accuracy=81.03%, ±3-day=12.50%\n",
      "MA: MAE=11.50, RMSE=13.13, MAPE=27.55%, Accuracy=72.45%, ±3-day=25.00%\n",
      "WMA: MAE=12.50, RMSE=13.73, MAPE=30.05%, Accuracy=69.95%, ±3-day=12.50%\n",
      "\n",
      "Next Cycle Predictions with Forecast Windows\n",
      "Exponential Smoothing: 2025-09-01 ± 7 days (2025-08-25 to 2025-09-08)\n",
      "ARIMA: 2025-09-05 ± 7 days (2025-08-29 to 2025-09-12)\n",
      "Moving Average: 2025-09-09 ± 5 days (2025-09-04 to 2025-09-14)\n",
      "Weighted Moving Average: 2025-09-16 ± 5 days (2025-09-11 to 2025-09-21)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_absolute_error, root_mean_squared_error\n",
    "\n",
    "# === 1. Load Data ===\n",
    "file_path = \"startDates.csv\"  # or \"cycles.xlsx\"\n",
    "if file_path.endswith(\".csv\"):\n",
    "    df = pd.read_csv(file_path)\n",
    "else:\n",
    "    df = pd.read_excel(file_path)\n",
    "\n",
    "df['start_date'] = pd.to_datetime(df['start_date'])\n",
    "df = df.sort_values('start_date').reset_index(drop=True)\n",
    "df['cycle_length'] = df['start_date'].diff().dt.days\n",
    "cycle_lengths = df['cycle_length'].dropna().reset_index(drop=True)\n",
    "\n",
    "# === 2. Train-Test Split ===\n",
    "train_size = int(len(cycle_lengths) * 0.8)\n",
    "train, test = cycle_lengths[:train_size], cycle_lengths[train_size:]\n",
    "\n",
    "# Function to compute metrics\n",
    "def compute_metrics(y_true, y_pred, tolerance=3):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    accuracy = 100 - mape\n",
    "    within_tol = (np.abs(y_true - y_pred) <= tolerance).mean() * 100\n",
    "    return mae, rmse, mape, accuracy, within_tol\n",
    "\n",
    "# === 3. Exponential Smoothing ===\n",
    "es_model = ExponentialSmoothing(train, trend=None, seasonal=None)\n",
    "es_fit = es_model.fit()\n",
    "es_forecast_test = es_fit.forecast(len(test))\n",
    "mae_es, rmse_es, mape_es, acc_es, tol3_es = compute_metrics(test, es_forecast_test)\n",
    "\n",
    "es_next_length = round(es_fit.forecast(1).iloc[0])\n",
    "es_last_start = df['start_date'].iloc[-1]\n",
    "es_window = 7  # ±7 days\n",
    "es_next_start = es_last_start + pd.Timedelta(days=es_next_length)\n",
    "es_next_range = (es_next_start - pd.Timedelta(days=es_window), es_next_start + pd.Timedelta(days=es_window))\n",
    "\n",
    "# === 4. ARIMA ===\n",
    "arima_model = ARIMA(train, order=(1,0,1))\n",
    "arima_fit = arima_model.fit()\n",
    "arima_forecast_test = arima_fit.forecast(len(test))\n",
    "mae_ar, rmse_ar, mape_ar, acc_ar, tol3_ar = compute_metrics(test, arima_forecast_test)\n",
    "\n",
    "arima_next_length = round(arima_fit.forecast(1).iloc[0])\n",
    "arima_window = 7  # ±7 days\n",
    "arima_next_start = es_last_start + pd.Timedelta(days=arima_next_length)\n",
    "arima_next_range = (arima_next_start - pd.Timedelta(days=arima_window), arima_next_start + pd.Timedelta(days=arima_window))\n",
    "\n",
    "# === 5. Simple Moving Average ===\n",
    "window = 3\n",
    "ma_forecast_test = []\n",
    "train_list = train.tolist()\n",
    "for i in range(len(test)):\n",
    "    ma_pred = np.mean(train_list[-window:])\n",
    "    ma_forecast_test.append(ma_pred)\n",
    "    train_list.append(test.iloc[i])\n",
    "ma_forecast_test = np.array(ma_forecast_test)\n",
    "mae_ma, rmse_ma, mape_ma, acc_ma, tol3_ma = compute_metrics(test, ma_forecast_test)\n",
    "\n",
    "ma_next_length = round(np.mean(cycle_lengths[-window:]))\n",
    "ma_window = 5  # ±5 days\n",
    "ma_next_start = es_last_start + pd.Timedelta(days=ma_next_length)\n",
    "ma_next_range = (ma_next_start - pd.Timedelta(days=ma_window), ma_next_start + pd.Timedelta(days=ma_window))\n",
    "\n",
    "# === 6. Weighted Moving Average ===\n",
    "weights = np.array([0.6, 0.3, 0.1])\n",
    "wma_forecast_test = []\n",
    "train_list = train.tolist()\n",
    "for i in range(len(test)):\n",
    "    wma_pred = np.dot(train_list[-3:], weights)\n",
    "    wma_forecast_test.append(wma_pred)\n",
    "    train_list.append(test.iloc[i])\n",
    "wma_forecast_test = np.array(wma_forecast_test)\n",
    "mae_wma, rmse_wma, mape_wma, acc_wma, tol3_wma = compute_metrics(test, wma_forecast_test)\n",
    "\n",
    "wma_next_length = round(np.dot(cycle_lengths[-3:], weights))\n",
    "wma_window = 5  # ±5 days\n",
    "wma_next_start = es_last_start + pd.Timedelta(days=wma_next_length)\n",
    "wma_next_range = (wma_next_start - pd.Timedelta(days=wma_window), wma_next_start + pd.Timedelta(days=wma_window))\n",
    "\n",
    "# === 7. Print Metrics & Next Cycle Predictions with Windows ===\n",
    "print(\"Model Performance on Test Data\")\n",
    "print(\"\"\"ES: MAE={:.2f}, RMSE={:.2f}, MAPE={:.2f}%, Accuracy={:.2f}%, ±3-day={:.2f}%\n",
    "ARIMA: MAE={:.2f}, RMSE={:.2f}, MAPE={:.2f}%, Accuracy={:.2f}%, ±3-day={:.2f}%\n",
    "MA: MAE={:.2f}, RMSE={:.2f}, MAPE={:.2f}%, Accuracy={:.2f}%, ±3-day={:.2f}%\n",
    "WMA: MAE={:.2f}, RMSE={:.2f}, MAPE={:.2f}%, Accuracy={:.2f}%, ±3-day={:.2f}%\"\"\"\n",
    "      .format(mae_es, rmse_es, mape_es, acc_es, tol3_es,\n",
    "              mae_ar, rmse_ar, mape_ar, acc_ar, tol3_ar,\n",
    "              mae_ma, rmse_ma, mape_ma, acc_ma, tol3_ma,\n",
    "              mae_wma, rmse_wma, mape_wma, acc_wma, tol3_wma))\n",
    "\n",
    "print(\"\\nNext Cycle Predictions with Forecast Windows\")\n",
    "print(f\"Exponential Smoothing: {es_next_start.date()} ± {es_window} days ({es_next_range[0].date()} to {es_next_range[1].date()})\")\n",
    "print(f\"ARIMA: {arima_next_start.date()} ± {arima_window} days ({arima_next_range[0].date()} to {arima_next_range[1].date()})\")\n",
    "print(f\"Moving Average: {ma_next_start.date()} ± {ma_window} days ({ma_next_range[0].date()} to {ma_next_range[1].date()})\")\n",
    "print(f\"Weighted Moving Average: {wma_next_start.date()} ± {wma_window} days ({wma_next_range[0].date()} to {wma_next_range[1].date()})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd413c0",
   "metadata": {},
   "source": [
    "Add more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2033a46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE=11.87, RMSE=14.65, MAPE=25.18%, Accuracy=74.82%\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- avg_cycle_length\n- avg_period_duration\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 50\u001b[39m\n\u001b[32m     44\u001b[39m last_cycle = cycle_lengths.iloc[-\u001b[32m1\u001b[39m]\n\u001b[32m     45\u001b[39m X_next = pd.DataFrame({\n\u001b[32m     46\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mprev_cycle_length\u001b[39m\u001b[33m'\u001b[39m: [last_cycle],\n\u001b[32m     47\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mavg_cycle_length\u001b[39m\u001b[33m'\u001b[39m: [avg_cycle_length],\n\u001b[32m     48\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mavg_period_duration\u001b[39m\u001b[33m'\u001b[39m: [avg_period_duration]\n\u001b[32m     49\u001b[39m })\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m next_cycle_length = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_next\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n\u001b[32m     51\u001b[39m next_cycle_date = df[\u001b[33m'\u001b[39m\u001b[33mstart_date\u001b[39m\u001b[33m'\u001b[39m].iloc[-\u001b[32m1\u001b[39m] + pd.Timedelta(days=\u001b[38;5;28mround\u001b[39m(next_cycle_length))\n\u001b[32m     52\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mPredicted next cycle start date: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnext_cycle_date.date()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mround\u001b[39m(next_cycle_length)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m days)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KomalChamyal\\OneDrive - ProArch\\Desktop\\cycle pred\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:298\u001b[39m, in \u001b[36mLinearModel.predict\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    284\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    285\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    286\u001b[39m \u001b[33;03m    Predict using the linear model.\u001b[39;00m\n\u001b[32m    287\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    296\u001b[39m \u001b[33;03m        Returns predicted values.\u001b[39;00m\n\u001b[32m    297\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m298\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_decision_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KomalChamyal\\OneDrive - ProArch\\Desktop\\cycle pred\\.venv\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:277\u001b[39m, in \u001b[36mLinearModel._decision_function\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_decision_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[32m    275\u001b[39m     check_is_fitted(\u001b[38;5;28mself\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m277\u001b[39m     X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcoo\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m     coef_ = \u001b[38;5;28mself\u001b[39m.coef_\n\u001b[32m    279\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m coef_.ndim == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KomalChamyal\\OneDrive - ProArch\\Desktop\\cycle pred\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2929\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2845\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mvalidate_data\u001b[39m(\n\u001b[32m   2846\u001b[39m     _estimator,\n\u001b[32m   2847\u001b[39m     /,\n\u001b[32m   (...)\u001b[39m\u001b[32m   2853\u001b[39m     **check_params,\n\u001b[32m   2854\u001b[39m ):\n\u001b[32m   2855\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Validate input data and set or check feature names and counts of the input.\u001b[39;00m\n\u001b[32m   2856\u001b[39m \n\u001b[32m   2857\u001b[39m \u001b[33;03m    This helper function should be used in an estimator that requires input\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2927\u001b[39m \u001b[33;03m        validated.\u001b[39;00m\n\u001b[32m   2928\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2929\u001b[39m     \u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_estimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2930\u001b[39m     tags = get_tags(_estimator)\n\u001b[32m   2931\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m tags.target_tags.required:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\KomalChamyal\\OneDrive - ProArch\\Desktop\\cycle pred\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:2787\u001b[39m, in \u001b[36m_check_feature_names\u001b[39m\u001b[34m(estimator, X, reset)\u001b[39m\n\u001b[32m   2784\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[32m   2785\u001b[39m     message += \u001b[33m\"\u001b[39m\u001b[33mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m2787\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[31mValueError\u001b[39m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- avg_cycle_length\n- avg_period_duration\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# === 2. Feature Engineering ===\n",
    "avg_cycle_length = cycle_lengths.mean()  # average cycle length\n",
    "avg_period_duration = 5  # given period lasts 5 days\n",
    "\n",
    "# Create features for regression\n",
    "# Use previous cycle length as feature + engineered features\n",
    "X = pd.DataFrame({\n",
    "    'prev_cycle_length': cycle_lengths.shift(1),\n",
    "    'avg_cycle_length': avg_cycle_length,\n",
    "    'avg_period_duration': avg_period_duration\n",
    "})\n",
    "Y = cycle_lengths\n",
    "\n",
    "# Drop first row with NaN\n",
    "X = X.dropna().reset_index(drop=True)\n",
    "Y = Y[1:].reset_index(drop=True)\n",
    "\n",
    "# === 3. Train-Test Split ===\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "Y_train, Y_test = Y[:train_size], Y[train_size:]\n",
    "\n",
    "# === 4. Linear Regression Model ===\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# === 5. Metrics ===\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    accuracy = 100 - mape\n",
    "    return mae, rmse, mape, accuracy\n",
    "\n",
    "mae, rmse, mape, acc = compute_metrics(Y_test, y_pred)\n",
    "print(f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape:.2f}%, Accuracy={acc:.2f}%\")\n",
    "\n",
    "# === 6. Predict Next Cycle ===\n",
    "last_cycle = cycle_lengths.iloc[-1]\n",
    "X_next = pd.DataFrame({\n",
    "    'prev_cycle_length': [last_cycle],\n",
    "    'avg_cycle_length': [avg_cycle_length],\n",
    "    'avg_period_duration': [avg_period_duration]\n",
    "})\n",
    "next_cycle_length = model.predict(X_next)[0]\n",
    "next_cycle_date = df['start_date'].iloc[-1] + pd.Timedelta(days=round(next_cycle_length))\n",
    "print(f\"Predicted next cycle start date: {next_cycle_date.date()} ({round(next_cycle_length)} days)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f3618ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE=13.28, RMSE=17.46, MAPE=28.45%, Accuracy=71.55%\n",
      "Predicted next cycle start date: 2025-08-28 (29 days)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# === 2. Feature Engineering ===\n",
    "avg_cycle_length = cycle_lengths.mean()  # average cycle length\n",
    "avg_period_duration = 5  # given period lasts 5 days\n",
    "\n",
    "# Create features for regression\n",
    "X = pd.DataFrame({\n",
    "    'prev_cycle_length': cycle_lengths.shift(1),\n",
    "    # 'avg_cycle_length': avg_cycle_length,\n",
    "    # 'avg_period_duration': avg_period_duration\n",
    "})\n",
    "Y = cycle_lengths\n",
    "\n",
    "# Drop first row with NaN\n",
    "X = X.dropna().reset_index(drop=True)\n",
    "Y = Y[1:].reset_index(drop=True)\n",
    "\n",
    "# === 3. Train-Test Split ===\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "Y_train, Y_test = Y[:train_size], Y[train_size:]\n",
    "\n",
    "# === 4. Random Forest Regressor ===\n",
    "model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# === 5. Metrics ===\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    accuracy = 100 - mape\n",
    "    return mae, rmse, mape, accuracy\n",
    "\n",
    "mae, rmse, mape, acc = compute_metrics(Y_test, y_pred)\n",
    "print(f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape:.2f}%, Accuracy={acc:.2f}%\")\n",
    "\n",
    "# === 6. Predict Next Cycle ===\n",
    "last_cycle = cycle_lengths.iloc[-1]\n",
    "X_next = pd.DataFrame({\n",
    "    'prev_cycle_length': [last_cycle],\n",
    "    # 'avg_cycle_length': [avg_cycle_length],\n",
    "    # 'avg_period_duration': [avg_period_duration]\n",
    "})\n",
    "next_cycle_length = model.predict(X_next)[0]\n",
    "next_cycle_date = df['start_date'].iloc[-1] + pd.Timedelta(days=round(next_cycle_length))\n",
    "print(f\"Predicted next cycle start date: {next_cycle_date.date()} ({round(next_cycle_length)} days)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5164bae9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'XGBRegressor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 30\u001b[39m\n\u001b[32m     26\u001b[39m Y_train, Y_test = Y[:train_size], Y[train_size:]\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# === 4. XGBoost Regressor ===\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m model = \u001b[43mXGBRegressor\u001b[49m(n_estimators=\u001b[32m200\u001b[39m, learning_rate=\u001b[32m0.1\u001b[39m, max_depth=\u001b[32m3\u001b[39m, random_state=\u001b[32m42\u001b[39m)\n\u001b[32m     31\u001b[39m model.fit(X_train, Y_train)\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Predict on test set\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'XGBRegressor' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# === 2. Feature Engineering ===\n",
    "avg_cycle_length = cycle_lengths.mean() # average cycle length\n",
    "avg_period_duration = 5 # given period lasts 5 days\n",
    "\n",
    "\n",
    "# Create lag features: previous 3 cycles\n",
    "lag_features = 3\n",
    "X = pd.DataFrame({\n",
    "'lag1': cycle_lengths.shift(1),\n",
    "'lag2': cycle_lengths.shift(2),\n",
    "'lag3': cycle_lengths.shift(3),\n",
    "'avg_cycle_length': avg_cycle_length,\n",
    "'avg_period_duration': avg_period_duration\n",
    "})\n",
    "Y = cycle_lengths\n",
    "\n",
    "\n",
    "# Drop rows with NaN due to lagging\n",
    "X = X.dropna().reset_index(drop=True)\n",
    "Y = Y[lag_features:].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# === 3. Train-Test Split ===\n",
    "train_size = int(len(X) * 0.8)\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "Y_train, Y_test = Y[:train_size], Y[train_size:]\n",
    "\n",
    "\n",
    "# === 4. XGBoost Regressor ===\n",
    "model = XGBRegressor(n_estimators=200, learning_rate=0.1, max_depth=3, random_state=42)\n",
    "model.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "# Predict on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# === 5. Metrics ===\n",
    "def compute_metrics(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = root_mean_squared_error(y_true, y_pred)\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "    accuracy = 100 - mape\n",
    "    return mae, rmse, mape, accuracy\n",
    "\n",
    "\n",
    "mae, rmse, mape, acc = compute_metrics(Y_test, y_pred)\n",
    "print(f\"MAE={mae:.2f}, RMSE={rmse:.2f}, MAPE={mape:.2f}%, Accuracy={acc:.2f}%\")\n",
    "\n",
    "\n",
    "# === 6. Predict Next Cycle ===\n",
    "last_cycles = cycle_lengths.iloc[-3:].tolist() # last 3 cycles\n",
    "X_next = pd.DataFrame({\n",
    "'lag1': [last_cycles[-1]],\n",
    "'lag2': [last_cycles[-2]],\n",
    "'lag3': [last_cycles[-3]],\n",
    "'avg_cycle_length': [avg_cycle_length],\n",
    "'avg_period_duration': [avg_period_duration]\n",
    "})\n",
    "next_cycle_length = model.predict(X_next)[0]\n",
    "next_cycle_date = df['start_date'].iloc[-1] + pd.Timedelta(days=round(next_cycle_length))\n",
    "print(f\"Predicted next cycle start date: {next_cycle_date.date()} ({round(next_cycle_length)} days)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
